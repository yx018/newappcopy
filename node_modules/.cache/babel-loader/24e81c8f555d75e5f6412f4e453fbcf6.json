{"ast":null,"code":"var _jsxFileName = \"/Users/yangxu/newapp/src/MyComponent.js\",\n    _s = $RefreshSig$();\n\nimport { OpenCvProvider, useOpenCv } from 'opencv-react';\nimport VideoCanvas from './VideoCanvas';\nimport { useEffect, useState } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nfunction MyComponent() {\n  _s();\n\n  const {\n    loaded,\n    cv\n  } = useOpenCv();\n  const video = document.getElementById(\"video\");\n  const canvas = document.getElementById(\"canvas\");\n  const img_previous = new Image(); // const img_now = new Image();\n  // let utils = new Utils();\n  // if (video.srcObject!= null)\n  // temCtx.drawImage(video, 0, 0);\n\n  const [count, setCount] = useState(0);\n  const [videoLoaded, setVideoLoaded] = useState(false);\n\n  const VideoUpload = () => {\n    // if (!videoLoaded) {\n    //     navigator.mediaDevices.getDisplayMedia({ video: { width: 1280, height: 720 }, audio: false })\n    //     .then(function(stream) {\n    //         console.log(stream);\n    //         video.srcObject = stream;\n    //         setVideoLoaded(true);\n    //         console.log(stream);\n    //         const settings = stream.getVideoTracks()[0].getSettings();\n    //         console.log(settings);\n    //         // console.log('width' + stream.offsetWidth);\n    //         video.height = settings.height; // // resize video size\n    //         video.width = settings.width;\n    //         canvas.width = settings.width; // resize canvas size\n    //         canvas.height = settings.height;\n    //         img_previous.src = \"https://en.wikipedia.org/wiki/Chinese_University_of_Hong_Kong#/media/File:CUHK.svg\";\n    //         video.play();\n    //         // GetFrame();\n    //     })\n    //     .then(()=> {\n    //         // utils.loadOpenCv(openCvReady);\n    //         console.log(cv);\n    //     })\n    //     .catch(function(err) {\n    //         console.log(\"No choose shared window! \" + err);\n    //     });\n    // }\n    navigator.mediaDevices.getDisplayMedia({\n      video: true,\n      audio: false\n    }).then(function (stream) {\n      video.srcObject = stream;\n      console.log(stream);\n      let settings = stream.getVideoTracks()[0].getSettings();\n      console.log(settings);\n      video.play();\n    }).then(() => {\n      // utils.loadOpenCv(openCvReady);\n      // console.log(cv.getBuildInformation());\n      console.log(OpenCvProvider.onLoaded);\n    }).catch(function (err) {\n      console.log(\"An error occurred! \" + err);\n    });\n  };\n\n  useEffect(() => {\n    if (cv) {\n      console.log(cv); // console.log(loaded);\n\n      console.log(\"count: \" + count);\n\n      if (video.srcObject != null) {\n        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n        let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n        let gray = new cv.Mat();\n        let cap = new cv.VideoCapture(video);\n        let faces = new cv.RectVector();\n        let classifier = new cv.CascadeClassifier();\n        let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\n        // let utils = new Utils();\n        // utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\n        //     classifier.load(faceCascadeFile); // in the callback, load the cascade from file \n        // });\n\n        console.log(classifier);\n        var begin = Date.now();\n        cap.read(src);\n        src.copyTo(dst);\n        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0); // try{\n        //     classifier.detectMultiScale(gray, faces, 1.1, 3, 0);\n        //     console.log(faces.size());\n        // }catch(err){\n        //     console.log(err);\n        // }\n        // for (let i = 0; i < faces.size(); ++i) {\n        //     let face = faces.get(i);\n        //     let point1 = new cv.Point(face.x, face.y);\n        //     let point2 = new cv.Point(face.x + face.width, face.y + face.height);\n        //     cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\n        // }\n\n        cv.imshow(\"canvas\", dst); // img_now.src = temCanvas.toDataURL('image/jpg');\n        // console.log(img_previous.src);\n        // console.log(img_now.src);\n        // console.log(img_previous  === img_now.src)\n        // if (img_previous.src != img_now.src){\n        //     img_previous.src = img_now.src;\n        //     console.log(\"AAA\");\n        //     // setCount(count+1);\n        // }\n      }\n\n      const FPS = 30; // const processVideo = () =>{\n      //     if (video.srcObject!= null)\n      //     {\n      //         // console.log(video.srcObject);\n      //         let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n      //         let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n      //         let gray = new cv.Mat();\n      //         let cap = new cv.VideoCapture(video);\n      //         let faces = new cv.RectVector();\n      //         let classifier = new cv.CascadeClassifier();\n      //         let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\n      //         // let utils = new Utils(cv, 'errorMessage');\n      //         // utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\n      //         //     classifier.load(faceCascadeFile); // in the callback, load the cascade from file \n      //         // });\n      //         console.log(classifier);\n      //         const detectFace = () => {\n      //             var begin = Date.now();\n      //             cap.read(src);\n      //             src.copyTo(dst);\n      //             cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\n      //             // try{\n      //             //     classifier.detectMultiScale(gray, faces, 1.1, 3, 0);\n      //             //     console.log(faces.size());\n      //             // }catch(err){\n      //             //     console.log(err);\n      //             // }\n      //             // for (let i = 0; i < faces.size(); ++i) {\n      //             //     let face = faces.get(i);\n      //             //     let point1 = new cv.Point(face.x, face.y);\n      //             //     let point2 = new cv.Point(face.x + face.width, face.y + face.height);\n      //             //     cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\n      //             // }\n      //             cv.imshow(\"canvas\", dst);\n      //             // schedule next one.\n      //             let delay = 1000/FPS - (Date.now() - begin);\n      //             setTimeout(detectFace, delay);\n      //             console.log(\"detect\");\n      //         }\n      //         setTimeout(detectFace, 0);\n      //         setTimeout(() => { clearInterval(timer) }, 0);\n      //     }\n      //     // console.log(\"AAA\");\n      //     let timer = setTimeout(processVideo, 10);\n      //     console.log(\"delay\");\n      // }\n      // // schedule first one.\n      // setTimeout(processVideo, 0);\n    }\n  }, [cv, video, count, videoLoaded]); // const cv = useOpenCv()\n  // console.log(cv)\n  // const video = document.getElementById(\"video\");\n  // let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n  // let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n  // let gray = new cv.Mat();\n  // let cap = new cv.VideoCapture(video);\n  // let faces = new cv.RectVector();\n  // let classifier = new cv.CascadeClassifier();\n  // let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\n  // classifier.load(faceCascadeFile);\n  // console.log(classifier);\n  // function onOpenUtilsReady() {\n  //     let utils = new Utils('errorMessage');\n  //     utils.loadOpenCv(() => {\n  //     let faceCascadeFile = 'haarcascade_frontalface_default.xml';\n  //         utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\n  //             document.getElementById('status').innerHTML = 'OpenCV.js is ready.';\n  //         });\n  //     });\n  // }\n\n  const onLoaded = cv => {\n    console.log('opencv loaded, cv');\n  };\n\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: /*#__PURE__*/_jsxDEV(\"p\", {\n      id: \"status\",\n      children: \"OpenCV.js is loading...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 216,\n      columnNumber: 9\n    }, this)\n  }, void 0, false);\n} // function openCvReady() {\n//     console.log(cv);\n//     let FPS = 30;\n//     let video = document.getElementById(\"cam_input\");\n//     let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n//     let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n//     let gray = new cv.Mat();\n//     let cap = new cv.VideoCapture(cam_input);\n//     let faces = new cv.RectVector();\n//     let classifier = new cv.CascadeClassifier();\n//     let minsize = new cv.Size(0, 0);\n//     let maxsize = new cv.Size(1000, 1000);\n//     let faceCascadeFile = 'haarcascade_frontalface_default.xml';\n//     utils.createFileFromUrl(faceCascadeFile, '../haarcascades/'+faceCascadeFile, () => {\n//         classifier.load(faceCascadeFile); // in the callback, load the cascade from file \n//     });\n//     let face_row = -1;\n//     let face_col = -1;\n//     let clip_width = video.width/5;\n//     let clip_height = video.height/5;\n//     function processVideo() {\n//         let begin = Date.now();\n//         if (video.srcObject!=null){\n//             cap.read(src);\n//             src.copyTo(dst);\n//             cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\n//             try{\n//                 classifier.detectMultiScale(gray, faces, 1.1, 3);\n//                 console.log(\"face size: \"+ faces.size());\n//             }catch(err){\n//                 console.log(err);\n//             }\n//             for (let i = 0; i < faces.size(); ++i) {\n//                 let face = faces.get(i);\n//                 // console.log(face);\n//                 let face_row = parseInt(face.y/clip_height);\n//                 let face_col = parseInt(face.x/clip_width);\n//                 let tmp_row = parseInt((face.y+face.height-5) / clip_height);\n//                 let tmp_col = parseInt((face.x+face.width-5) / clip_width);\n//                 // console.log([face_row, face_col, tmp_row, tmp_col]);\n//                 if (face.width>=clip_width || face.height>=clip_height || tmp_row!=face_row || tmp_col!=face_col)\n//                     continue;\n//                 let point1 = new cv.Point(face.x, face.y);\n//                 let point2 = new cv.Point(face.x + face.width, face.y + face.height);\n//                 cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\n//             }\n//             cv.imshow(\"canvas_output\", dst);\n//         }\n//         // schedule next one.\n//         let delay = 1000/FPS - (Date.now() - begin);\n//         setTimeout(processVideo, delay);\n//     }\n//     // schedule first one.\n//     setTimeout(processVideo, 0); \n// }\n// function Utils() {\n//     let self = this;\n//     this.createFileFromUrl = function(path, url, callback) {\n//         console.log(cv);\n//         let request = new XMLHttpRequest();\n//         request.open('GET', url, true);\n//         request.responseType = 'arraybuffer';\n//         request.onload = function(ev) {\n//             if (request.readyState === 4) {\n//                 if (request.status === 200) {\n//                     let data = new Uint8Array(request.response);\n//                     cv.FS_createDataFile('/', path, data, true, false, false);\n//                     callback();\n//                 } else {\n//                     self.printError('Failed to load ' + url + ' status: ' + request.status);\n//                 }\n//             }\n//         };\n//         request.send();\n//     };\n//     const OPENCV_URL = './opencv/opencv.js';\n//     this.loadOpenCv = function(onloadCallback) {\n//         let script = document.createElement('script');\n//         script.setAttribute('async', '');\n//         script.setAttribute('type', 'text/javascript');\n//         script.addEventListener('load', async () => {\n//             if (cv.getBuildInformation)\n//             {\n//                 console.log(cv.getBuildInformation());\n//                 onloadCallback();\n//             }\n//             else\n//             {\n//                 // WASM\n//                 if (cv instanceof Promise) {\n//                     cv = await cv;\n//                     console.log(cv.getBuildInformation());\n//                     onloadCallback();\n//                 } else {\n//                     cv['onRuntimeInitialized']=()=>{  //satisfy this condition\n//                         console.log(cv.getBuildInformation()); \n//                         onloadCallback();\n//                     }\n//                 }\n//             }\n//         });\n//         script.addEventListener('error', () => {\n//             self.printError('Failed to load ' + OPENCV_URL);\n//         });\n//         script.src = OPENCV_URL;\n//         let node = document.getElementsByTagName('script')[0];\n//         node.parentNode.insertBefore(script, node);\n//     };\n// }\n\n\n_s(MyComponent, \"h9ro0BHJdAOcVjzaOypUggy9LRU=\", false, function () {\n  return [useOpenCv];\n});\n\n_c = MyComponent;\nexport default MyComponent;\n\nvar _c;\n\n$RefreshReg$(_c, \"MyComponent\");","map":{"version":3,"sources":["/Users/yangxu/newapp/src/MyComponent.js"],"names":["OpenCvProvider","useOpenCv","VideoCanvas","useEffect","useState","MyComponent","loaded","cv","video","document","getElementById","canvas","img_previous","Image","count","setCount","videoLoaded","setVideoLoaded","VideoUpload","navigator","mediaDevices","getDisplayMedia","audio","then","stream","srcObject","console","log","settings","getVideoTracks","getSettings","play","onLoaded","catch","err","src","Mat","height","width","CV_8UC4","dst","CV_8UC1","gray","cap","VideoCapture","faces","RectVector","classifier","CascadeClassifier","faceCascadeFile","begin","Date","now","read","copyTo","cvtColor","COLOR_RGBA2GRAY","imshow","FPS"],"mappings":";;;AAAA,SAASA,cAAT,EAAyBC,SAAzB,QAA0C,cAA1C;AACA,OAAOC,WAAP,MAAwB,eAAxB;AACA,SAAQC,SAAR,EAAmBC,QAAnB,QAAkC,OAAlC;;;;AAMA,SAASC,WAAT,GAAuB;AAAA;;AACnB,QAAM;AAAEC,IAAAA,MAAF;AAAUC,IAAAA;AAAV,MAAiBN,SAAS,EAAhC;AACA,QAAMO,KAAK,GAAGC,QAAQ,CAACC,cAAT,CAAwB,OAAxB,CAAd;AACA,QAAMC,MAAM,GAAGF,QAAQ,CAACC,cAAT,CAAwB,QAAxB,CAAf;AACA,QAAME,YAAY,GAAG,IAAIC,KAAJ,EAArB,CAJmB,CAKnB;AACA;AACA;AACA;;AAEA,QAAM,CAACC,KAAD,EAAQC,QAAR,IAAoBX,QAAQ,CAAC,CAAD,CAAlC;AACA,QAAM,CAACY,WAAD,EAAcC,cAAd,IAAgCb,QAAQ,CAAC,KAAD,CAA9C;;AAEA,QAAMc,WAAW,GAAG,MAAK;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGAC,IAAAA,SAAS,CAACC,YAAV,CAAuBC,eAAvB,CAAuC;AAAEb,MAAAA,KAAK,EAAE,IAAT;AAAec,MAAAA,KAAK,EAAE;AAAtB,KAAvC,EACCC,IADD,CACM,UAASC,MAAT,EAAiB;AACnBhB,MAAAA,KAAK,CAACiB,SAAN,GAAkBD,MAAlB;AACAE,MAAAA,OAAO,CAACC,GAAR,CAAYH,MAAZ;AACA,UAAII,QAAQ,GAAGJ,MAAM,CAACK,cAAP,GAAwB,CAAxB,EAA2BC,WAA3B,EAAf;AACAJ,MAAAA,OAAO,CAACC,GAAR,CAAYC,QAAZ;AACApB,MAAAA,KAAK,CAACuB,IAAN;AACH,KAPD,EAQCR,IARD,CAQM,MAAK;AACP;AACA;AACAG,MAAAA,OAAO,CAACC,GAAR,CAAY3B,cAAc,CAACgC,QAA3B;AACH,KAZD,EAaCC,KAbD,CAaO,UAASC,GAAT,EAAc;AACjBR,MAAAA,OAAO,CAACC,GAAR,CAAY,wBAAwBO,GAApC;AACH,KAfD;AAgBH,GAlDD;;AAoDA/B,EAAAA,SAAS,CAAC,MAAM;AACZ,QAAII,EAAJ,EAAQ;AACJmB,MAAAA,OAAO,CAACC,GAAR,CAAYpB,EAAZ,EADI,CAEJ;;AACAmB,MAAAA,OAAO,CAACC,GAAR,CAAY,YAAWb,KAAvB;;AAEA,UAAIN,KAAK,CAACiB,SAAN,IAAkB,IAAtB,EAA2B;AAEvB,YAAIU,GAAG,GAAG,IAAI5B,EAAE,CAAC6B,GAAP,CAAW5B,KAAK,CAAC6B,MAAjB,EAAyB7B,KAAK,CAAC8B,KAA/B,EAAsC/B,EAAE,CAACgC,OAAzC,CAAV;AACA,YAAIC,GAAG,GAAG,IAAIjC,EAAE,CAAC6B,GAAP,CAAW5B,KAAK,CAAC6B,MAAjB,EAAyB7B,KAAK,CAAC8B,KAA/B,EAAsC/B,EAAE,CAACkC,OAAzC,CAAV;AACA,YAAIC,IAAI,GAAG,IAAInC,EAAE,CAAC6B,GAAP,EAAX;AACA,YAAIO,GAAG,GAAG,IAAIpC,EAAE,CAACqC,YAAP,CAAoBpC,KAApB,CAAV;AACA,YAAIqC,KAAK,GAAG,IAAItC,EAAE,CAACuC,UAAP,EAAZ;AACA,YAAIC,UAAU,GAAG,IAAIxC,EAAE,CAACyC,iBAAP,EAAjB;AACA,YAAIC,eAAe,GAAG,qCAAtB,CARuB,CAQsC;AAC7D;AACA;AACA;AACA;;AACAvB,QAAAA,OAAO,CAACC,GAAR,CAAYoB,UAAZ;AAGA,YAAIG,KAAK,GAAGC,IAAI,CAACC,GAAL,EAAZ;AACAT,QAAAA,GAAG,CAACU,IAAJ,CAASlB,GAAT;AACAA,QAAAA,GAAG,CAACmB,MAAJ,CAAWd,GAAX;AACAjC,QAAAA,EAAE,CAACgD,QAAH,CAAYf,GAAZ,EAAiBE,IAAjB,EAAuBnC,EAAE,CAACiD,eAA1B,EAA2C,CAA3C,EAnBuB,CAoBvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACAjD,QAAAA,EAAE,CAACkD,MAAH,CAAU,QAAV,EAAoBjB,GAApB,EAhCuB,CAkCvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACH;;AAED,YAAMkB,GAAG,GAAG,EAAZ,CAlDI,CAoDJ;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEH;AACJ,GA5GQ,EA4GN,CAACnD,EAAD,EAAKC,KAAL,EAAWM,KAAX,EAAkBE,WAAlB,CA5GM,CAAT,CAjEmB,CA+KnB;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,QAAMgB,QAAQ,GAAIzB,EAAD,IAAQ;AACrBmB,IAAAA,OAAO,CAACC,GAAR,CAAY,mBAAZ;AACH,GAFD;;AAIA,sBACI;AAAA,2BAEA;AAAG,MAAA,EAAE,EAAC,QAAN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAFA,mBADJ;AAQH,C,CAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;GAvUStB,W;UACkBJ,S;;;KADlBI,W;AA2UT,eAAeA,WAAf","sourcesContent":["import { OpenCvProvider, useOpenCv } from 'opencv-react'\nimport VideoCanvas from './VideoCanvas';\nimport {useEffect, useState} from 'react'\n\n\n\n\n\nfunction MyComponent() {\n    const { loaded, cv } = useOpenCv();\n    const video = document.getElementById(\"video\");\n    const canvas = document.getElementById(\"canvas\");\n    const img_previous = new Image();\n    // const img_now = new Image();\n    // let utils = new Utils();\n    // if (video.srcObject!= null)\n    // temCtx.drawImage(video, 0, 0);\n\n    const [count, setCount] = useState(0);\n    const [videoLoaded, setVideoLoaded] = useState(false);\n\n    const VideoUpload = () =>{\n        // if (!videoLoaded) {\n        //     navigator.mediaDevices.getDisplayMedia({ video: { width: 1280, height: 720 }, audio: false })\n        //     .then(function(stream) {\n        //         console.log(stream);\n        //         video.srcObject = stream;\n        //         setVideoLoaded(true);\n        //         console.log(stream);\n\n        //         const settings = stream.getVideoTracks()[0].getSettings();\n        //         console.log(settings);\n        //         // console.log('width' + stream.offsetWidth);\n\n        //         video.height = settings.height; // // resize video size\n        //         video.width = settings.width;\n        //         canvas.width = settings.width; // resize canvas size\n        //         canvas.height = settings.height;\n        //         img_previous.src = \"https://en.wikipedia.org/wiki/Chinese_University_of_Hong_Kong#/media/File:CUHK.svg\";\n                \n        //         video.play();\n        //         // GetFrame();\n                \n        //     })\n        //     .then(()=> {\n        //         // utils.loadOpenCv(openCvReady);\n        //         console.log(cv);\n        //     })\n        //     .catch(function(err) {\n        //         console.log(\"No choose shared window! \" + err);\n        //     });\n            \n        // }\n\n        \n        navigator.mediaDevices.getDisplayMedia({ video: true, audio: false })\n        .then(function(stream) {\n            video.srcObject = stream;\n            console.log(stream);\n            let settings = stream.getVideoTracks()[0].getSettings();\n            console.log(settings);\n            video.play();\n        })\n        .then(()=> {\n            // utils.loadOpenCv(openCvReady);\n            // console.log(cv.getBuildInformation());\n            console.log(OpenCvProvider.onLoaded);\n        })\n        .catch(function(err) {\n            console.log(\"An error occurred! \" + err);\n        });\n    }\n    \n    useEffect(() => {\n        if (cv) {\n            console.log(cv);\n            // console.log(loaded);\n            console.log(\"count: \"+ count);\n            \n            if (video.srcObject!= null){\n\n                let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n                let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n                let gray = new cv.Mat();\n                let cap = new cv.VideoCapture(video);\n                let faces = new cv.RectVector();\n                let classifier = new cv.CascadeClassifier();\n                let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\n                // let utils = new Utils();\n                // utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\n                //     classifier.load(faceCascadeFile); // in the callback, load the cascade from file \n                // });\n                console.log(classifier);\n                \n                \n                var begin = Date.now();\n                cap.read(src);\n                src.copyTo(dst);\n                cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\n                // try{\n                //     classifier.detectMultiScale(gray, faces, 1.1, 3, 0);\n                //     console.log(faces.size());\n                // }catch(err){\n                //     console.log(err);\n                // }\n                // for (let i = 0; i < faces.size(); ++i) {\n                //     let face = faces.get(i);\n                //     let point1 = new cv.Point(face.x, face.y);\n                //     let point2 = new cv.Point(face.x + face.width, face.y + face.height);\n                //     cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\n                // }\n                cv.imshow(\"canvas\", dst);\n                \n                // img_now.src = temCanvas.toDataURL('image/jpg');\n                // console.log(img_previous.src);\n                // console.log(img_now.src);\n                // console.log(img_previous  === img_now.src)\n                // if (img_previous.src != img_now.src){\n                //     img_previous.src = img_now.src;\n                //     console.log(\"AAA\");\n                //     // setCount(count+1);\n                // }\n            }\n\n            const FPS = 30;\n\n            // const processVideo = () =>{\n                \n            //     if (video.srcObject!= null)\n            //     {\n            //         // console.log(video.srcObject);\n            //         let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n            //         let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n            //         let gray = new cv.Mat();\n            //         let cap = new cv.VideoCapture(video);\n            //         let faces = new cv.RectVector();\n            //         let classifier = new cv.CascadeClassifier();\n            //         let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\n            //         // let utils = new Utils(cv, 'errorMessage');\n            //         // utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\n            //         //     classifier.load(faceCascadeFile); // in the callback, load the cascade from file \n            //         // });\n            //         console.log(classifier);\n                    \n            //         const detectFace = () => {\n            //             var begin = Date.now();\n            //             cap.read(src);\n            //             src.copyTo(dst);\n            //             cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\n            //             // try{\n            //             //     classifier.detectMultiScale(gray, faces, 1.1, 3, 0);\n            //             //     console.log(faces.size());\n            //             // }catch(err){\n            //             //     console.log(err);\n            //             // }\n            //             // for (let i = 0; i < faces.size(); ++i) {\n            //             //     let face = faces.get(i);\n            //             //     let point1 = new cv.Point(face.x, face.y);\n            //             //     let point2 = new cv.Point(face.x + face.width, face.y + face.height);\n            //             //     cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\n            //             // }\n            //             cv.imshow(\"canvas\", dst);\n                        \n                        \n            //             // schedule next one.\n            //             let delay = 1000/FPS - (Date.now() - begin);\n            //             setTimeout(detectFace, delay);\n            //             console.log(\"detect\");\n            //         }\n            //         setTimeout(detectFace, 0);\n            //         setTimeout(() => { clearInterval(timer) }, 0);\n            //     }\n            //     // console.log(\"AAA\");\n            //     let timer = setTimeout(processVideo, 10);\n            //     console.log(\"delay\");\n                \n            // }\n            // // schedule first one.\n            // setTimeout(processVideo, 0);\n\n        }\n    }, [cv, video,count, videoLoaded])\n\n    // const cv = useOpenCv()\n    // console.log(cv)\n\n    // const video = document.getElementById(\"video\");\n    // let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n    // let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n    // let gray = new cv.Mat();\n    // let cap = new cv.VideoCapture(video);\n    // let faces = new cv.RectVector();\n    // let classifier = new cv.CascadeClassifier();\n\n    // let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml\n    // classifier.load(faceCascadeFile);\n    // console.log(classifier);\n\n    // function onOpenUtilsReady() {\n    //     let utils = new Utils('errorMessage');\n    //     utils.loadOpenCv(() => {\n    //     let faceCascadeFile = 'haarcascade_frontalface_default.xml';\n    //         utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {\n    //             document.getElementById('status').innerHTML = 'OpenCV.js is ready.';\n    //         });\n    //     });\n    // }\n\n    const onLoaded = (cv) => {\n        console.log('opencv loaded, cv')\n    }\n\n    return (\n        <>\n        \n        <p id=\"status\">OpenCV.js is loading...</p>\n        \n        </>\n        \n    )\n}\n\n// function openCvReady() {\n//     console.log(cv);\n//     let FPS = 30;\n//     let video = document.getElementById(\"cam_input\");\n//     let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\n//     let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);\n//     let gray = new cv.Mat();\n//     let cap = new cv.VideoCapture(cam_input);\n//     let faces = new cv.RectVector();\n//     let classifier = new cv.CascadeClassifier();\n//     let minsize = new cv.Size(0, 0);\n//     let maxsize = new cv.Size(1000, 1000);\n//     let faceCascadeFile = 'haarcascade_frontalface_default.xml';\n//     utils.createFileFromUrl(faceCascadeFile, '../haarcascades/'+faceCascadeFile, () => {\n//         classifier.load(faceCascadeFile); // in the callback, load the cascade from file \n//     });\n//     let face_row = -1;\n//     let face_col = -1;\n//     let clip_width = video.width/5;\n//     let clip_height = video.height/5;\n//     function processVideo() {\n//         let begin = Date.now();\n//         if (video.srcObject!=null){\n//             cap.read(src);\n//             src.copyTo(dst);\n//             cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);\n//             try{\n//                 classifier.detectMultiScale(gray, faces, 1.1, 3);\n//                 console.log(\"face size: \"+ faces.size());\n//             }catch(err){\n//                 console.log(err);\n//             }\n//             for (let i = 0; i < faces.size(); ++i) {\n//                 let face = faces.get(i);\n//                 // console.log(face);\n//                 let face_row = parseInt(face.y/clip_height);\n//                 let face_col = parseInt(face.x/clip_width);\n\n//                 let tmp_row = parseInt((face.y+face.height-5) / clip_height);\n//                 let tmp_col = parseInt((face.x+face.width-5) / clip_width);\n//                 // console.log([face_row, face_col, tmp_row, tmp_col]);\n//                 if (face.width>=clip_width || face.height>=clip_height || tmp_row!=face_row || tmp_col!=face_col)\n//                     continue;\n\n//                 let point1 = new cv.Point(face.x, face.y);\n//                 let point2 = new cv.Point(face.x + face.width, face.y + face.height);\n//                 cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);\n//             }\n//             cv.imshow(\"canvas_output\", dst);\n//         }\n//         // schedule next one.\n//         let delay = 1000/FPS - (Date.now() - begin);\n//         setTimeout(processVideo, delay);\n//     }\n//     // schedule first one.\n//     setTimeout(processVideo, 0); \n// }\n\n// function Utils() {\n//     let self = this;\n//     this.createFileFromUrl = function(path, url, callback) {\n//         console.log(cv);\n//         let request = new XMLHttpRequest();\n//         request.open('GET', url, true);\n//         request.responseType = 'arraybuffer';\n//         request.onload = function(ev) {\n//             if (request.readyState === 4) {\n//                 if (request.status === 200) {\n//                     let data = new Uint8Array(request.response);\n//                     cv.FS_createDataFile('/', path, data, true, false, false);\n//                     callback();\n//                 } else {\n//                     self.printError('Failed to load ' + url + ' status: ' + request.status);\n//                 }\n//             }\n//         };\n//         request.send();\n        \n//     };\n\n//     const OPENCV_URL = './opencv/opencv.js';\n//     this.loadOpenCv = function(onloadCallback) {\n//         let script = document.createElement('script');\n//         script.setAttribute('async', '');\n//         script.setAttribute('type', 'text/javascript');\n//         script.addEventListener('load', async () => {\n//             if (cv.getBuildInformation)\n//             {\n//                 console.log(cv.getBuildInformation());\n//                 onloadCallback();\n//             }\n//             else\n//             {\n//                 // WASM\n//                 if (cv instanceof Promise) {\n//                     cv = await cv;\n//                     console.log(cv.getBuildInformation());\n//                     onloadCallback();\n//                 } else {\n//                     cv['onRuntimeInitialized']=()=>{  //satisfy this condition\n//                         console.log(cv.getBuildInformation()); \n//                         onloadCallback();\n//                     }\n//                 }\n//             }\n//         });\n//         script.addEventListener('error', () => {\n//             self.printError('Failed to load ' + OPENCV_URL);\n//         });\n//         script.src = OPENCV_URL;\n//         let node = document.getElementsByTagName('script')[0];\n//         node.parentNode.insertBefore(script, node);\n//     };\n// }\n\n\n\nexport default MyComponent;\n\n\n"]},"metadata":{},"sourceType":"module"}